{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a40ee961",
   "metadata": {},
   "source": [
    "# 선행 연구들 기반으로 단어 리스트별 상관 분석해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e77f734",
   "metadata": {},
   "source": [
    "## Baek et al.(2023)\n",
    "Proficiency versus lexical processing efficiency as a measure of L2\n",
    "lexical quality: Individual differences in word‑frequency effects in L2\n",
    "visual word recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c2d0dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ed4f46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1_Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.613000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.205177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.465000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.575000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.310000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         L1_Freq\n",
       "count  30.000000\n",
       "mean    4.613000\n",
       "std     0.205177\n",
       "min     4.420000\n",
       "25%     4.465000\n",
       "50%     4.575000\n",
       "75%     4.667500\n",
       "max     5.310000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HF_df = pd.DataFrame(\n",
    "    {\n",
    "        'Word': ['right', 'think', 'never', 'sorry', 'thank', 'love', 'maybe', 'help', 'these', 'night', 'first', 'great', 'life', 'still', 'those', 'other', 'stop', 'name', 'money', 'place', 'kind', 'hello', 'years', 'leave', 'girl', 'three', 'wrong', 'might', 'house', 'baby'],\n",
    "        'L1_Freq': [5.31, 5.14, 4.84, 4.78, 4.76, 4.76, 4.67, 4.67, 4.66, 4.65, 4.63, 4.62, 4.61, 4.60, 4.58, 4.57, 4.56, 4.52, 4.51, 4.49, 4.48, 4.48, 4.46, 4.46, 4.45, 4.44, 4.43, 4.42, 4.42, 4.42],\n",
    "    }\n",
    ")\n",
    "HF_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c1357d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1_Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.501333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.082827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.557500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.710000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         L1_Freq\n",
       "count  30.000000\n",
       "mean    2.501333\n",
       "std     0.082827\n",
       "min     2.360000\n",
       "25%     2.437500\n",
       "50%     2.485000\n",
       "75%     2.557500\n",
       "max     2.710000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LF_df = pd.DataFrame(\n",
    "    {\n",
    "        'Word': ['skirt', 'creek', 'laser', 'stove', 'chili', \n",
    "                 'armor', 'draft', 'jelly', 'shelf', 'hobby', \n",
    "                 'tubes', 'peach', 'booty', 'cloth', 'debts', \n",
    "                 'glue', 'spine', 'clip', 'tomb', 'scope', \n",
    "                 'dove', 'vest', 'lone', 'buyer', 'mode', \n",
    "                 'waist', 'thorn', 'flick', 'hound', 'crow'],\n",
    "        'L1_Freq': [2.71, 2.66, 2.64, 2.59, 2.58, \n",
    "                    2.57, 2.57, 2.56, 2.55, 2.55, \n",
    "                    2.53, 2.51, 2.50, 2.49, 2.49, \n",
    "                    2.48, 2.47, 2.46, 2.46, 2.46, \n",
    "                    2.46, 2.46, 2.43, 2.42, 2.42, \n",
    "                    2.42, 2.42, 2.41, 2.41, 2.36],\n",
    "    }\n",
    ")\n",
    "LF_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f55d4b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSAT_lexicon_proj_file_path = os.path.join(os.path.dirname(os.path.dirname(Path.cwd())), 'Corpora', 'merged_corpora', 'CSAT_E_lexicon.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d1243d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Length</th>\n",
       "      <th>CSAT_Freq</th>\n",
       "      <th>CSAT_only_Freq</th>\n",
       "      <th>Textbook_only_Freq</th>\n",
       "      <th>Freq_HAL</th>\n",
       "      <th>SUBTLWF</th>\n",
       "      <th>CSAT_RFreq</th>\n",
       "      <th>CSAT_only_RFreq</th>\n",
       "      <th>Textbook_only_RFreq</th>\n",
       "      <th>Ortho_N_CSAT</th>\n",
       "      <th>Ortho_N_CSAT(only)</th>\n",
       "      <th>Ortho_N_Textbook(only)</th>\n",
       "      <th>Ortho_N</th>\n",
       "      <th>OLD20_CSAT</th>\n",
       "      <th>OLD20_CSAT(only)</th>\n",
       "      <th>OLD20_Textbook(only)</th>\n",
       "      <th>OLD</th>\n",
       "      <th>SUBTLCD</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1284.0</td>\n",
       "      <td>1098.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>10610626</td>\n",
       "      <td>20415.27</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.65</td>\n",
       "      <td>1.45</td>\n",
       "      <td>99.93</td>\n",
       "      <td>minor|NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aah</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>222</td>\n",
       "      <td>52.71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.85</td>\n",
       "      <td>7.56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaron</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10806</td>\n",
       "      <td>14.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.93</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aback</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>387</td>\n",
       "      <td>0.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.18</td>\n",
       "      <td>RB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abacus</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>513</td>\n",
       "      <td>0.24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40476</th>\n",
       "      <td>zoom</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4920</td>\n",
       "      <td>3.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.70</td>\n",
       "      <td>1.29</td>\n",
       "      <td>VB|NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40477</th>\n",
       "      <td>zooming</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>523</td>\n",
       "      <td>0.63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.31</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40478</th>\n",
       "      <td>zooms</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>385</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.04</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40479</th>\n",
       "      <td>zucchini</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>314</td>\n",
       "      <td>0.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40480</th>\n",
       "      <td>zurich</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1770</td>\n",
       "      <td>2.43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.80</td>\n",
       "      <td>0.74</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40481 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  Length  CSAT_Freq  CSAT_only_Freq  Textbook_only_Freq  \\\n",
       "0             a       1     1284.0          1098.0               186.0   \n",
       "1           aah       3        NaN             NaN                 NaN   \n",
       "2         aaron       5        NaN             NaN                 NaN   \n",
       "3         aback       5        NaN             NaN                 NaN   \n",
       "4        abacus       6        NaN             NaN                 NaN   \n",
       "...         ...     ...        ...             ...                 ...   \n",
       "40476      zoom       4        NaN             NaN                 NaN   \n",
       "40477   zooming       7        NaN             NaN                 NaN   \n",
       "40478     zooms       5        NaN             NaN                 NaN   \n",
       "40479  zucchini       8        NaN             NaN                 NaN   \n",
       "40480    zurich       6        NaN             NaN                 NaN   \n",
       "\n",
       "       Freq_HAL   SUBTLWF  CSAT_RFreq  CSAT_only_RFreq  Textbook_only_RFreq  \\\n",
       "0      10610626  20415.27    0.001284         0.001098             0.000186   \n",
       "1           222     52.71         NaN              NaN                  NaN   \n",
       "2         10806     14.65         NaN              NaN                  NaN   \n",
       "3           387      0.29         NaN              NaN                  NaN   \n",
       "4           513      0.24         NaN              NaN                  NaN   \n",
       "...         ...       ...         ...              ...                  ...   \n",
       "40476      4920      3.55         NaN              NaN                  NaN   \n",
       "40477       523      0.63         NaN              NaN                  NaN   \n",
       "40478       385      0.06         NaN              NaN                  NaN   \n",
       "40479       314      0.96         NaN              NaN                  NaN   \n",
       "40480      1770      2.43         NaN              NaN                  NaN   \n",
       "\n",
       "       Ortho_N_CSAT  Ortho_N_CSAT(only)  Ortho_N_Textbook(only)  Ortho_N  \\\n",
       "0               1.0                 1.0                     1.0        1   \n",
       "1               NaN                 NaN                     NaN        2   \n",
       "2               NaN                 NaN                     NaN        3   \n",
       "3               NaN                 NaN                     NaN        0   \n",
       "4               NaN                 NaN                     NaN        0   \n",
       "...             ...                 ...                     ...      ...   \n",
       "40476           NaN                 NaN                     NaN        4   \n",
       "40477           NaN                 NaN                     NaN        3   \n",
       "40478           NaN                 NaN                     NaN        3   \n",
       "40479           NaN                 NaN                     NaN        0   \n",
       "40480           NaN                 NaN                     NaN        0   \n",
       "\n",
       "       OLD20_CSAT  OLD20_CSAT(only)  OLD20_Textbook(only)   OLD  SUBTLCD  \\\n",
       "0             1.5               1.5                  1.65  1.45    99.93   \n",
       "1             NaN               NaN                   NaN  1.85     7.56   \n",
       "2             NaN               NaN                   NaN  1.85     1.93   \n",
       "3             NaN               NaN                   NaN  1.95     0.18   \n",
       "4             NaN               NaN                   NaN  2.90     0.12   \n",
       "...           ...               ...                   ...   ...      ...   \n",
       "40476         NaN               NaN                   NaN  1.70     1.29   \n",
       "40477         NaN               NaN                   NaN  1.85     0.31   \n",
       "40478         NaN               NaN                   NaN  1.80     0.04   \n",
       "40479         NaN               NaN                   NaN  3.75     0.25   \n",
       "40480         NaN               NaN                   NaN  2.80     0.74   \n",
       "\n",
       "            POS  \n",
       "0      minor|NN  \n",
       "1           NaN  \n",
       "2            NN  \n",
       "3            RB  \n",
       "4            NN  \n",
       "...         ...  \n",
       "40476     VB|NN  \n",
       "40477        VB  \n",
       "40478        VB  \n",
       "40479        NN  \n",
       "40480        NN  \n",
       "\n",
       "[40481 rows x 20 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(CSAT_lexicon_proj_file_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f438565b",
   "metadata": {},
   "source": [
    "야 조졌다. 왜 이건 또 상관이 많이 다를까..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16ecb44c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1_Freq</th>\n",
       "      <th>CSAT_Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L1_Freq</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.302281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSAT_Freq</th>\n",
       "      <td>0.302281</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            L1_Freq  CSAT_Freq\n",
       "L1_Freq    1.000000   0.302281\n",
       "CSAT_Freq  0.302281   1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df, HF_df, how='inner', on='Word')[['L1_Freq', 'CSAT_Freq']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d1d1ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1_Freq</th>\n",
       "      <th>CSAT_Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L1_Freq</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.242348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSAT_Freq</th>\n",
       "      <td>-0.242348</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            L1_Freq  CSAT_Freq\n",
       "L1_Freq    1.000000  -0.242348\n",
       "CSAT_Freq -0.242348   1.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df, LF_df, how='inner', on='Word')[['L1_Freq', 'CSAT_Freq']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a1ac7",
   "metadata": {},
   "source": [
    "그렇다면 상관이 높은 것 찾아보자. HAL이나 SUBTLEX랑은 비슷하겠지?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2a73f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1_Freq</th>\n",
       "      <th>SUBTLWF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L1_Freq</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUBTLWF</th>\n",
       "      <td>0.994295</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          L1_Freq   SUBTLWF\n",
       "L1_Freq  1.000000  0.994295\n",
       "SUBTLWF  0.994295  1.000000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df, LF_df, how='inner', on='Word')[['L1_Freq', 'SUBTLWF']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c0f6e23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1_Freq</th>\n",
       "      <th>Freq_HAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L1_Freq</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.102702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Freq_HAL</th>\n",
       "      <td>-0.102702</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           L1_Freq  Freq_HAL\n",
       "L1_Freq   1.000000 -0.102702\n",
       "Freq_HAL -0.102702  1.000000"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df, LF_df, how='inner', on='Word')[['L1_Freq', 'Freq_HAL']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8ce034",
   "metadata": {},
   "source": [
    "SUBTLEX에서 뽑아온게 맞네. 근데 HAL이랑은  왜 이렇게 달라..? 아예 거의 상관이 없다는 수준의 값인데 흠,,\n",
    "\n",
    "그렇다면 corpus 전체으 상관값이 높더라도 corpus가 비슷하다고 할 수 없다는 걸 시사한다고 볼 수 있겠지.\n",
    "\n",
    "그렇다면 단순 빈도만으로는 설명할 수 잇는데 한계가 있다고 하고, corpus간의 유사성을 분석하는 기존 선행 연구들을 찾아볼 필요가 있겠네"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e093f",
   "metadata": {},
   "source": [
    "## Wouter et al. (2008)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575271b9",
   "metadata": {},
   "source": [
    "The frequency effect in second-language\n",
    "visual word recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91ada2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>balcony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>birthrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>catacomb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ceiling</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ceremony</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word\n",
       "0    balcony\n",
       "1  birthrate\n",
       "2   catacomb\n",
       "3    ceiling\n",
       "4   ceremony"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HF_df = pd.DataFrame(\n",
    "    {\n",
    "        'Word': ['balcony', 'birthrate', 'catacomb', 'ceiling', 'ceremony', \n",
    "                 'crystal', 'detour', 'deviation', 'diver', 'enquirer', \n",
    "                 'fairness', 'flame', 'font', 'graph', 'lawn', \n",
    "                 'liberty', 'melon', 'peanut', 'pirate', 'portion', \n",
    "                 'puma', 'salary', 'seaman', 'stair', 'waist'\n",
    "                 ]\n",
    "    }\n",
    ")\n",
    "HF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1066860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>council</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>couple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>court</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>daughter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Word\n",
       "0  afternoon\n",
       "1    council\n",
       "2     couple\n",
       "3      court\n",
       "4   daughter"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LF_df = pd.DataFrame(\n",
    "    {\n",
    "        'Word': ['afternoon', 'council', 'couple', 'court', 'daughter', \n",
    "                 'dress', 'floor', 'freedom', 'garden', 'health', \n",
    "                 'income', 'industry', 'member', 'morning', 'process', \n",
    "                 'promise', 'result', 'river', 'secrertary', 'sign', \n",
    "                 'teacher', 'town', 'truth', 'union', 'worker'\n",
    "                 ]\n",
    "    }\n",
    ")\n",
    "LF_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d31b4a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freq_HAL</th>\n",
       "      <th>CSAT_Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Freq_HAL</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.565935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSAT_Freq</th>\n",
       "      <td>0.565935</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Freq_HAL  CSAT_Freq\n",
       "Freq_HAL   1.000000   0.565935\n",
       "CSAT_Freq  0.565935   1.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df, HF_df, how='inner', on='Word')[['Freq_HAL', 'CSAT_Freq']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "de4e316e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBTLWF</th>\n",
       "      <th>CSAT_Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SUBTLWF</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.054567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSAT_Freq</th>\n",
       "      <td>-0.054567</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SUBTLWF  CSAT_Freq\n",
       "SUBTLWF    1.000000  -0.054567\n",
       "CSAT_Freq -0.054567   1.000000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df, HF_df, how='inner', on='Word')[['SUBTLWF', 'CSAT_Freq']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505bd270",
   "metadata": {},
   "source": [
    "앤 또 HAL이랑 비슷하네."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b5e421",
   "metadata": {},
   "source": [
    "# Xiaocong Chen et al.(2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ae5bb4",
   "metadata": {},
   "source": [
    "On the predictive validity of various corpus-based frequency norms in L2 English lexical processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7ce955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_df = pd.DataFrame(\n",
    "    {\n",
    "        'Word': ['absolute', 'accrue', 'acid', 'admiral', 'affair', \n",
    "                 'again', 'agreed', 'allowed', 'amazement', 'american', \n",
    "                 'analysis', 'anchor', 'angriest', 'announces', 'another', \n",
    "                 'arisen', 'ashes', 'assign', 'atmosphere', 'attempt', \n",
    "                 'autonomous', 'available', 'avoid', 'away', 'awkward',\n",
    "                 'babies', 'balconies', 'bank', 'being', 'best',\n",
    "                 'bill', 'bleak', 'boast', 'body', 'bombers',\n",
    "                 'box', 'bravest', 'breed', 'broader', 'bump',\n",
    "                 'burial', 'bus', 'business', 'buy', 'calmer',\n",
    "                 'capable', 'capture', 'cart', 'caught', 'characterize',\n",
    "                 'checks', 'children', 'chosen', 'cigar', 'class',\n",
    "                 'classified', 'coalition', 'coincide', 'coke', 'combat', \n",
    "                 'comes', 'comfy', 'comparison', 'computer', 'conceal', \n",
    "                 'conference', 'confession', 'confide', 'confirm', 'conquer', \n",
    "                 'consulting', 'contact', 'core', 'corridor', 'corroborate', \n",
    "                 'country', 'course', 'covering', 'creation', 'credit', 'crouch', \n",
    "                 'cultural', 'curl', 'currently', 'danger', 'day', 'dazzle', 'dealt', \n",
    "                 'dearer', 'debut', 'decent', 'declares', 'densest',\n",
    "                 'development', 'different', 'diminishes', 'diplomat', 'discovery', \n",
    "                 'dishes', 'disliked', 'distance', 'distributed', 'division', 'dominant', 'done', 'down',\n",
    "                 'drawn', 'drives', 'driveway', 'dug', 'during', 'easiest', 'east', 'eaten', 'ecstatic',\n",
    "                 'edge', 'edifice', 'employer', 'emulation', 'enough', 'entertainment', 'environment', 'episodes', 'excellent', 'excuse', 'experience', 'extracted',\n",
    "                 'factories', 'fade', 'fancier', 'fans', 'fantastic', 'far', 'fatter', 'fear', 'feet', 'few',\n",
    "                 'fiercest', 'file', 'fire', 'flagrant', 'flirt', 'fold', 'forced', 'frees', 'fuel', 'fullest',\n",
    "                 'funniest', 'gathered', 'geese', 'generations', 'gets', 'glasses', 'god', 'gold',\n",
    "                 'good', 'gospel', 'government', 'gross', 'guys', 'habit', 'happen', 'having',\n",
    "                 'healthier', 'heard', 'heavy', 'hid', 'highest', 'himself', 'honey', 'hose', 'human', 'hybrid', 'implies', 'incredibly', 'induction', 'information',\n",
    "                 'installed', 'international', 'island', 'issue', 'its', 'jaunt', 'jewel', 'jingle', 'job',\n",
    "                 'keep', 'kind', 'knives', 'knowledge', 'known', 'last', 'later', 'latex', 'launch',\n",
    "                 'leagues', 'lifeboat', 'linking', 'listed', 'loathed', 'looking', 'luckier', 'lumber', 'maintains', 'major', 'manhood', 'manor', 'mean', 'meetings', 'mice',\n",
    "                 'minister', 'mirror', 'morning', 'mouths', 'move', 'must', 'nastier', 'necessary', 'nerve', 'never', 'nights', 'noisier', 'normal', 'numbers', 'office', 'older',\n",
    "                 'opportunity', 'orientation', 'outbreak', 'pamper', 'particle', 'patron',\n",
    "                 'peaches', 'pebble', 'perhaps', 'perimeter', 'periodic', 'picking', 'place',\n",
    "                 'played', 'pleasure', 'plunging', 'plus', 'possession', 'pound', 'presidential',\n",
    "                 'prevent', 'probably', 'problems', 'products', 'prototypes',\n",
    "                 'provides', 'punched', 'purchases', 'purest', 'quarter', 'quieter', 'reasonably', 'received', 'reef', 'relating', 'relationship', 'requires', 'response',\n",
    "                 'responsible', 'reveal', 'revival', 'ribbon', 'richest', 'right', 'rises', 'roast',\n",
    "                 'room', 'rough', 'ruler', 'running', 'sadism', 'sat', 'saying', 'second', 'security',\n",
    "                 'seems', 'selection', 'sentencing', 'separating', 'services', 'session',\n",
    "                 'shorter', 'shout', 'silence', 'slam', 'slaughter', 'slow', 'sometimes', 'south',\n",
    "                 'square', 'stakes', 'stamp', 'starting', 'state', 'statistics', 'steady', 'stories',\n",
    "                 'strain', 'strongest', 'student', 'successor', 'sung', 'surprise', 'surveillance',\n",
    "                 'tagging', 'taxes', 'tear', 'telescope', 'territories', 'terror', 'textual', 'theme',\n",
    "                 'thieves', 'those', 'thought', 'tile', 'till', 'today', 'together', 'tolerance', 'torches',\n",
    "                 'total', 'touchy', 'toxicology', 'tragedies', 'trail', 'transport', 'trouble',\n",
    "                 'turned', 'twist', 'type', 'uglier', 'uncover', 'under', 'understand', 'universities', 'unless', 'upbringing', 'visitor', 'vocal', 'vulnerable', 'walk', 'wavy',\n",
    "                 'way', 'weapon', 'weekend', 'weird', 'welcome', 'went', 'wide', 'withhold',\n",
    "                 'wonder', 'work', 'worn', 'worthiest', 'wound', 'yarn', 'year', 'yes', 'yonder', 'zone',\n",
    "                 ]\n",
    "    }\n",
    ")\n",
    "len(F_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8ca0cf88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freq_HAL</th>\n",
       "      <th>CSAT_Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Freq_HAL</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.840761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSAT_Freq</th>\n",
       "      <td>0.840761</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Freq_HAL  CSAT_Freq\n",
       "Freq_HAL   1.000000   0.840761\n",
       "CSAT_Freq  0.840761   1.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df, F_df, how='inner', on='Word')[['Freq_HAL', 'CSAT_Freq']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4eff1c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBTLWF</th>\n",
       "      <th>CSAT_Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SUBTLWF</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.579647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSAT_Freq</th>\n",
       "      <td>0.579647</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SUBTLWF  CSAT_Freq\n",
       "SUBTLWF    1.000000   0.579647\n",
       "CSAT_Freq  0.579647   1.000000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df, F_df, how='inner', on='Word')[['SUBTLWF', 'CSAT_Freq']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a18c44",
   "metadata": {},
   "source": [
    "# Shusaku et el.(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289f98fc",
   "metadata": {},
   "source": [
    "Word learning and lexicalization in a second language: Evidence\n",
    "from the Prime lexicality effect in masked form priming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70748338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_prime_F_df = pd.DataFrame(\n",
    "    {\n",
    "        'Word': ['abode', 'aglow', 'bunk', 'colt', 'knack', \n",
    "                 'lank', 'mucky', 'omen', 'slant', 'skid', \n",
    "                 'stow', 'latch', 'awry', 'bash', 'blob', \n",
    "                 'chasm', 'coda', 'fount', 'nigih', 'douse'\n",
    "                 ]\n",
    "    }\n",
    ")\n",
    "len(related_prime_F_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "863ebed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBTLWF</th>\n",
       "      <th>CSAT_Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.47</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.55</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.27</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.35</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.92</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.71</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SUBTLWF  CSAT_Freq\n",
       "0      0.65        NaN\n",
       "1      0.47        NaN\n",
       "2      0.55        NaN\n",
       "3      3.27        NaN\n",
       "4      1.18        NaN\n",
       "5      6.27        NaN\n",
       "6      0.35        NaN\n",
       "7      0.14        NaN\n",
       "8      5.24        NaN\n",
       "9      0.80        NaN\n",
       "10     2.49        NaN\n",
       "11     0.02        NaN\n",
       "12     1.92        NaN\n",
       "13     0.18        NaN\n",
       "14     1.71        NaN\n",
       "15     2.18        NaN\n",
       "16     1.14        NaN\n",
       "17     1.25        NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df, related_prime_F_df, how='inner', on='Word')[['SUBTLWF', 'CSAT_Freq']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "df3f285a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_prime_F_df = pd.DataFrame(\n",
    "    {\n",
    "        'Word': ['flirt', 'furry', 'yarn', 'kick', 'flute', \n",
    "                 'tend', 'sheet', 'flux', 'curly', 'puff', \n",
    "                 'lava', 'bells', 'edit', 'twin', 'jive', \n",
    "                 'wired', 'sink', 'media', 'romp', 'inch'\n",
    "                 ]\n",
    "    }\n",
    ")\n",
    "len(control_prime_F_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9ec42546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBTLWF</th>\n",
       "      <th>CSAT_Freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SUBTLWF</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CSAT_Freq</th>\n",
       "      <td>0.941369</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            SUBTLWF  CSAT_Freq\n",
       "SUBTLWF    1.000000   0.941369\n",
       "CSAT_Freq  0.941369   1.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df, control_prime_F_df, how='inner', on='Word')[['SUBTLWF', 'CSAT_Freq']].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30d76a1",
   "metadata": {},
   "source": [
    "# Adel et al.(2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c5f803",
   "metadata": {},
   "source": [
    "The elusive impact of L2 immersion on translation priming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b56d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "control_prime_F_df = pd.DataFrame(\n",
    "    {\n",
    "        'Word': ['law', 'year', 'love', 'mess', 'hate', \n",
    "                 'harm', 'aunt', 'boss', 'side', 'chill', \n",
    "                 'night', 'twin', 'party', 'pity', 'mix', \n",
    "                 'size', 'trip', 'anger', 'dream', 'bunch',\n",
    "                 'dirt', 'haste', 'half', 'life', 'place', \n",
    "                 'glow', 'roar', 'smell', 'work', 'army', \n",
    "                 'chess', 'crowd', 'end', 'fact', 'hustle', \n",
    "                 'morning', 'smile', 'clash', 'strain', 'strike',\n",
    "                 'truce', 'level', 'bounce', 'bribe', 'feat', \n",
    "                 'plunge', 'prayer', 'drought', 'raise', 'scope', \n",
    "\n",
    "                 'chapter', 'truth', 'flu', 'task', 'owner', \n",
    "                 'winter', 'youth', 'craving', 'buzz', 'charm',\n",
    "                 'design', 'surge', 'hangover', 'hunger', 'prank', \n",
    "                 'setback', 'flurry', 'praise', 'profile', 'relief', \n",
    "                 'script', 'meeting', 'sadness', 'weather', 'belief', \n",
    "                 'change', 'deceit', 'delight', 'help', 'glimpse',\n",
    "                 'guest', 'madness', 'friend', 'pursuit', 'height', \n",
    "                 'scolding', 'sense', 'shortage', 'trait', 'injury', \n",
    "                 'void', 'width', 'alibi', 'pleasure', 'coldness', \n",
    "                 'demise', 'outcry', 'essay', 'flight', 'goodness',\n",
    "                 'ghost', 'handful', 'hoax', 'intake', \n",
    "\n",
    "                 'mayhem', 'misstep', 'mortgage', 'medley', 'noise', \n",
    "                 'payroll', 'retreat', 'miracle', 'threat', 'gang', \n",
    "                 'success', 'whisper', 'famine', 'beauty', 'award',\n",
    "                 'asset', 'cousin', 'defeat', 'plot', 'effort', \n",
    "                 'goddess', 'clue', 'harvest', 'proof', 'breed', \n",
    "                 'burial', 'laziness', 'gamble', 'gossip', 'guilt',\n",
    "                 'health', 'insanity', 'jeopardy', 'jump', 'measure', \n",
    "                 'portrait', 'realm', 'affair', 'soul', 'stealth', \n",
    "                 'warmth', 'query', 'advice', 'business', 'heaven',\n",
    "                 'outbreak', 'nuisance', 'shortcut', 'likeness', 'arrival', \n",
    "                 'closure', 'people', 'death', 'delivery', \n",
    "                 ]\n",
    "    }\n",
    ")\n",
    "len(control_prime_F_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f688fbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
